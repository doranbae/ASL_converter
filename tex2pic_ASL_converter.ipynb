{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "# Pipeline_v4\n",
    "Updated: The output structure follow's Sharmila's note from July 16th.<br>\n",
    "<br>\n",
    "This notebook takes sentence input and retrieves corresponding images. <br>\n",
    "(1) Set dic_url <br>\n",
    "(2) Command: (this will prompt an input box) <br>\n",
    "<br>\n",
    "job = Text2pic() <br>\n",
    "text2pic_result = job.take_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import PIL.Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os.path import splitext\n",
    "from IPython.display import Image, display\n",
    "from difflib import SequenceMatcher\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import uni2bigram,uni_bi_list,score_dic, find_all_ngram_cases,find_max_list,find_image,max_score_sentence,mk_sentence_cases,mk_score_dic,mk_ngram_li\n",
    "from random import randint\n",
    "\n",
    "#Import for segmenter\n",
    "import collections\n",
    "import copy\n",
    "import unittest\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from IPython.display import display, HTML\n",
    "import part2_helpers\n",
    "import treeviz\n",
    "import pcfg\n",
    "import cky, cky_test\n",
    "from nltk import ProbabilisticTree\n",
    "import cPickle\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set image directory\n",
    "im_url_ = '/Users/db91057/Documents/PROJECTS/Berkeley/image_retrieval/downloads/baseline/'\n",
    "#set dictionary directory\n",
    "dic_url_ = '/Users/db91057/Documents/PROJECTS/Berkeley/image_retrieval/downloads/asl_baseline_dictionary.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Text2pic():\n",
    "    def take_input(self): \n",
    "        print \"Please enter a sentence: \",\n",
    "        self.sentence = raw_input()\n",
    "        try: \n",
    "            self.segmenter_()\n",
    "            self.load_pic_dic()\n",
    "            self.filterASL()\n",
    "            self.image_pool()\n",
    "            self.recommended_visual_sentence()\n",
    "            self.final_result = self.mk_json_output()\n",
    "            return self.final_result\n",
    "        except:\n",
    "            print(\"Segmenter error\")\n",
    "        \n",
    "    def load_pic_dic(self):\n",
    "        \"\"\"\n",
    "        Loads the image metadata dic and converts to dictionary\n",
    "        Sample: ['JJ', 'www.handspeak.com, Kids ASL', 'blue.png', 1.0]\n",
    "                \n",
    "        \"\"\"\n",
    "        path_to_im_dic = dic_url_\n",
    "        self.dic_df = pd.read_csv(path_to_im_dic)\n",
    "        self.im_dic = self.dic_df.set_index('tag').T.to_dict('list')\n",
    "        return self.im_dic\n",
    "            \n",
    "    def segmenter_(self):\n",
    "        with open(\"wsj_fullPTB_grammar.pkl\", \"r\") as savedModFile:\n",
    "            reloadedModel = cPickle.load(savedModFile)\n",
    "            # segmented list\n",
    "            reload(cky)\n",
    "            mySentence = self.sentence\n",
    "            cky.parseSentence(mySentence, reloadedModel)\n",
    "            # Flat list\n",
    "            derivation = cky.CKY(mySentence.split(), reloadedModel, 'S')\n",
    "            print(derivation.pos())\n",
    "            self.seg_output = derivation.pos()\n",
    "            return self.seg_output\n",
    "        \n",
    "    def filterASL(self):\n",
    "        # posList is a list of (word, POS) tuples\n",
    "        # First eliminate determiners, is / are being verbs\n",
    "        DTSet = set(['the', 'an', 'this', 'that', 'these', 'those'])\n",
    "        QtySet = set(['many', 'few','some'])\n",
    "        requirementSet = set(['must', 'might', 'may', 'should', 'could', 'ought'])\n",
    "        ElimSet = QtySet.union(DTSet).union(requirementSet)\n",
    "    \n",
    "        # eliminate tuples with words in the ElimSet\n",
    "        self.filterPosList = [self.seg_output[i] for i in range(len(self.seg_output)) if self.seg_output[i][0].lower() not in ElimSet]\n",
    "        return self.filterPosList\n",
    "    \n",
    "    def image_pool(self): \n",
    "        image_id = []\n",
    "        self.english_sentence = []\n",
    "        #visual_sentence = []\n",
    "        for comp in self.filterPosList:\n",
    "            kw = comp[0]\n",
    "            self.english_sentence.append(kw)\n",
    "            pos = comp[1]\n",
    "            if kw in self.im_dic.keys():\n",
    "                if self.im_dic.get(kw)[0] == str(pos):\n",
    "                    image_data_, vis_sentence = find_image(kw,self.im_dic,image_id)\n",
    "                    #visual_sentence.append(vis_sentence)\n",
    "                    #print(\"Yes, I have that image:\", kw)\n",
    "                else:\n",
    "                    uncleared_li = kw.rsplit(\" \", 1)\n",
    "                    for unc in uncleared_li:\n",
    "                        if unc in self.im_dic.keys():\n",
    "                            image_data_, vis_sentence = find_image(kw,self.im_dic,image_id)\n",
    "                            #visual_sentence.append(vis_sentence)\n",
    "                            #print(\"Yes, I have that image:\", unc)\n",
    "                        else:\n",
    "                            print(\"Sorry no image for:\", unc)\n",
    "            else:\n",
    "                uncleared_li = kw.rsplit(\" \", 1)\n",
    "                for unc in uncleared_li:\n",
    "                    if unc in self.im_dic.keys():\n",
    "                        image_data_, vis_sentence = find_image(kw,self.im_dic,image_id)\n",
    "                        #visual_sentence.append(vis_sentence)\n",
    "                        #print(\"Yes, I have that image:\", unc)\n",
    "                    else: \n",
    "                        print(\"Sorry no image for:\", unc)\n",
    "        try:\n",
    "            self.image_data = image_data_\n",
    "            return(self.image_data)\n",
    "        except:\n",
    "            self.image_data = []\n",
    "            return self.image_data\n",
    "    \n",
    "    def recommended_visual_sentence(self):\n",
    "        mk_score_dic(self.im_dic, 2, self.filterPosList)\n",
    "        self.all_cases = mk_sentence_cases(self.filterPosList, 2)\n",
    "        self.score_dic_ = mk_score_dic(self.im_dic, 1, self.filterPosList)\n",
    "        self.max_ngram_case = max_score_sentence(self.all_cases,self.score_dic_)\n",
    "        list_ = []\n",
    "        for comp in self.max_ngram_case:\n",
    "            kw = comp[0]\n",
    "            pos = comp[1]\n",
    "            if kw in self.im_dic.keys():\n",
    "                image_id_ = self.im_dic.get(kw)[3]\n",
    "                image_id = image_id_.strip().split(\";\")\n",
    "                random_number = randint(0, len(image_id)-1)\n",
    "                random_selection = image_id[random_number] \n",
    "                list_.append(random_selection)\n",
    "            else:\n",
    "                print(\"Sorry no such word\", kw) \n",
    "        #print(list_)\n",
    "        self.recommended_best = list_       \n",
    "        #print(\"best_images:\", self.recommended_best)\n",
    "        return self.recommended_best    \n",
    "    \n",
    "    def mk_json_output(self):\n",
    "        json_tmp = {}\n",
    "        json_tmp[\"english_sentence\"] = self.sentence\n",
    "        json_tmp[\"bag_of_images\"] = self.image_data\n",
    "        json_tmp[\"visual_sentence\"] = self.recommended_best\n",
    "        json_format = json.dumps(json_tmp)\n",
    "        return(json_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a sentence: girl play ball\n",
      " [('girl', NN), ('play', VB), ('ball', NN)]\n"
     ]
    }
   ],
   "source": [
    "job = Text2pic()\n",
    "text2pic_result = job.take_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"english_sentence\": \"girl play ball\", \"bag_of_images\": [\"100209\", \"100170\", \"100127\", \"110170\", \"120127\", \"130127\", \"100056\", \"123450\"], \"visual_sentence\": [\"100209\", \"100657\"]}\n"
     ]
    }
   ],
   "source": [
    "print(text2pic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
